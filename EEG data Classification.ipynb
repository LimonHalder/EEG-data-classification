{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f20d66ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pyeeg as pe\n",
    "import pickle as pickle\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec7291",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "098764d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = [1,2,3,4,6,11,13,17,19,20,21,25,29,31] #14 Channels chosen to fit Emotiv Epoch+\n",
    "band = [4,8,12,16,25,45] #5 bands\n",
    "window_size = 256 #Averaging band power of 2 sec\n",
    "step_size = 16 #Each 0.125 sec update once\n",
    "sample_rate = 128 #Sampling rate of 128 Hz\n",
    "subjectList = ['01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32']\n",
    "#List of subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7ec4680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_power(X, Band, Fs):\n",
    "    \"\"\"Compute power in each frequency bin specified by Band from FFT result of\n",
    "    X. By default, X is a real signal.\n",
    "\n",
    "    Note\n",
    "    -----\n",
    "    A real signal can be synthesized, thus not real.\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "\n",
    "    Band\n",
    "        list\n",
    "\n",
    "        boundary frequencies (in Hz) of bins. They can be unequal bins, e.g.\n",
    "        [0.5,4,7,12,30] which are delta, theta, alpha and beta respectively.\n",
    "        You can also use range() function of Python to generate equal bins and\n",
    "        pass the generated list to this function.\n",
    "\n",
    "        Each element of Band is a physical frequency and shall not exceed the\n",
    "        Nyquist frequency, i.e., half of sampling frequency.\n",
    "\n",
    "     X\n",
    "        list\n",
    "\n",
    "        a 1-D real time series.\n",
    "\n",
    "    Fs\n",
    "        integer\n",
    "\n",
    "        the sampling rate in physical frequency\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "\n",
    "    Power\n",
    "        list\n",
    "\n",
    "        spectral power in each frequency bin.\n",
    "\n",
    "    Power_ratio\n",
    "        list\n",
    "\n",
    "        spectral power in each frequency bin normalized by total power in ALL\n",
    "        frequency bins.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    C = np.fft.fft(X)\n",
    "    C = abs(C)\n",
    "    Power = np.zeros(len(Band) - 1)\n",
    "    for Freq_Index in range(0, len(Band) - 1):\n",
    "        Freq = float(Band[Freq_Index])\n",
    "        Next_Freq = float(Band[Freq_Index + 1])\n",
    "        Power[Freq_Index] = sum(\n",
    "            C[int(np.floor(Freq / Fs * len(X))): \n",
    "                int(np.floor(Next_Freq / Fs * len(X)))]\n",
    "        )\n",
    "    Power_Ratio = Power / sum(Power)\n",
    "    return Power, Power_Ratio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4af2dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FFT_Processing (sub, channel, band, window_size, step_size, sample_rate):\n",
    "    '''\n",
    "    arguments:  string subject\n",
    "                list channel indice\n",
    "                list band\n",
    "                int window size for FFT\n",
    "                int step size for FFT\n",
    "                int sample rate for FFT\n",
    "    return:     void\n",
    "    '''\n",
    "    meta = []\n",
    "    with open('dataset\\s' + sub + '.dat', 'rb') as file:\n",
    "\n",
    "        subject = pickle.load(file, encoding='latin1') #resolve the python 2 data problem by encoding : latin1\n",
    "\n",
    "        for i in range (0,40):\n",
    "            # loop over 0-39 trails\n",
    "            data = subject[\"data\"][i]\n",
    "            labels = subject[\"labels\"][i]\n",
    "            start = 0;\n",
    "\n",
    "            while start + window_size < data.shape[1]:\n",
    "                meta_array = []\n",
    "                meta_data = [] #meta vector for analysis\n",
    "                for j in channel:\n",
    "                    X = data[j][start : start + window_size] #Slice raw data over 2 sec, at interval of 0.125 sec\n",
    "                    Y = bin_power(X, band, sample_rate) #FFT over 2 sec of channel j, in seq of theta, alpha, low beta, high beta, gamma\n",
    "                    meta_data = meta_data + list(Y[0])\n",
    "\n",
    "                meta_array.append(np.array(meta_data))\n",
    "                meta_array.append(labels)\n",
    "\n",
    "                meta.append(np.array(meta_array))    \n",
    "                start = start + step_size\n",
    "                \n",
    "        meta = np.array(meta)\n",
    "        np.save('out\\s' + sub, meta, allow_pickle=True, fix_imports=True)\n",
    "\n",
    "def testing (M, L, model):\n",
    "    '''\n",
    "    arguments:  M: testing dataset\n",
    "                L: testing dataset label\n",
    "                model: scikit-learn model\n",
    "\n",
    "    return:     void\n",
    "    '''\n",
    "    output = model.predict(M[0:78080:32])\n",
    "    label = L[0:78080:32]\n",
    "\n",
    "    k = 0\n",
    "    l = 0\n",
    "\n",
    "    for i in range(len(label)):\n",
    "        k = k + (output[i] - label[i])*(output[i] - label[i]) #square difference \n",
    "\n",
    "        #a good guess\n",
    "        if (output[i] > 5 and label[i] > 5):\n",
    "            l = l + 1\n",
    "        elif (output[i] < 5 and label[i] <5):\n",
    "            l = l + 1\n",
    "\n",
    "    print (\"l2 error:\", k/len(label), \"classification accuracy:\", l / len(label),l, len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c97342cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_1228\\3602070678.py:33: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  meta.append(np.array(meta_array))\n"
     ]
    }
   ],
   "source": [
    "for subjects in subjectList:\n",
    "    FFT_Processing (subjects, channel, band, window_size, step_size, sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1afae673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training dataset: (468480, 70) (468480, 4)\n",
      "testing dataset: (78080, 70) (78080, 4)\n",
      "validation dataset: (78080, 70) (78080, 4)\n"
     ]
    }
   ],
   "source": [
    "#for subjects in subjectList:\n",
    "data_training = []\n",
    "label_training = []\n",
    "data_testing = []\n",
    "label_testing = []\n",
    "data_validation = []\n",
    "label_validation = []\n",
    "\n",
    "for subjects in subjectList:\n",
    "\n",
    "    with open('out\\s' + subjects + '.npy', 'rb') as file:\n",
    "        sub = np.load(file,allow_pickle=True)\n",
    "        for i in range (0,sub.shape[0]):\n",
    "            if i % 8 == 0:\n",
    "                data_testing.append(sub[i][0])\n",
    "                label_testing.append(sub[i][1])\n",
    "            elif i % 8 == 1:\n",
    "                data_validation.append(sub[i][0])\n",
    "                label_validation.append(sub[i][1])\n",
    "            else:\n",
    "                data_training.append(sub[i][0])\n",
    "                label_training.append(sub[i][1])\n",
    "\n",
    "np.save('out\\data_training', np.array(data_training), allow_pickle=True, fix_imports=True)\n",
    "np.save('out\\label_training', np.array(label_training), allow_pickle=True, fix_imports=True)\n",
    "print(\"training dataset:\", np.array(data_training).shape, np.array(label_training).shape)\n",
    "\n",
    "np.save('out\\data_testing', np.array(data_testing), allow_pickle=True, fix_imports=True)\n",
    "np.save('out\\label_testing', np.array(label_testing), allow_pickle=True, fix_imports=True)\n",
    "print(\"testing dataset:\", np.array(data_testing).shape, np.array(label_testing).shape)\n",
    "\n",
    "np.save('out\\data_validation', np.array(data_validation), allow_pickle=True, fix_imports=True)\n",
    "np.save('out\\label_validation', np.array(label_validation), allow_pickle=True, fix_imports=True)\n",
    "print(\"validation dataset:\", np.array(data_validation).shape, np.array(label_validation).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4df63bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('out\\data_training.npy', 'rb') as fileTrain:\n",
    "    X  = np.load(fileTrain)\n",
    "    \n",
    "with open('out\\label_training.npy', 'rb') as fileTrainL:\n",
    "    Y  = np.load(fileTrainL)\n",
    "    \n",
    "X = normalize(X)\n",
    "Z = np.ravel(Y[:, [1]])\n",
    "\n",
    "Arousal_Train = np.ravel(Y[:, [0]])\n",
    "Valence_Train = np.ravel(Y[:, [1]])\n",
    "Domain_Train = np.ravel(Y[:, [2]])\n",
    "Like_Train = np.ravel(Y[:, [3]])\n",
    "\n",
    "\n",
    "\n",
    "with open('out\\data_validation.npy', 'rb') as fileTrain:\n",
    "    M  = np.load(fileTrain)\n",
    "    \n",
    "with open('out\\label_validation.npy', 'rb') as fileTrainL:\n",
    "    N  = np.load(fileTrainL)\n",
    "\n",
    "M = normalize(M)\n",
    "L = np.ravel(N[:, [1]])\n",
    "\n",
    "Arousal_Test = np.ravel(N[:, [0]])\n",
    "Valence_Test = np.ravel(N[:, [1]])\n",
    "Domain_Test = np.ravel(N[:, [2]])\n",
    "Like_Test = np.ravel(N[:, [3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98ae858e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVR()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVR</label><div class=\"sk-toggleable__content\"><pre>SVR()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVR()\n",
    "clf.fit(X[0:468480:32], Z[0:468480:32])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5cbd41c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 error: 1.8834456735387388 classification accuracy: 0.8319672131147541 2030 2440\n"
     ]
    }
   ],
   "source": [
    "Val_R = RandomForestRegressor(n_estimators=512, n_jobs=6)\n",
    "Val_R.fit(X[0:468480:32], Valence_Train[0:468480:32])\n",
    "testing (M, Valence_Test, Val_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a5d54a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 error: 2.082245762870198 classification accuracy: 0.8319672131147541 2030 2440\n"
     ]
    }
   ],
   "source": [
    "Aro_R = RandomForestRegressor(n_estimators=512, n_jobs=6)\n",
    "Aro_R.fit(X[0:468480:32], Arousal_Train[0:468480:32])\n",
    "testing (M, Arousal_Test, Aro_R)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1d4508d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 error: 1.8270069410769632 classification accuracy: 0.8200819672131148 2001 2440\n"
     ]
    }
   ],
   "source": [
    "Dom_R = RandomForestRegressor(n_estimators=512, n_jobs=6)\n",
    "Dom_R.fit(X[0:468480:32], Domain_Train[0:468480:32])\n",
    "testing (M, Domain_Test, Dom_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8c0d6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 error: 2.485309634352356 classification accuracy: 0.8508196721311475 2076 2440\n"
     ]
    }
   ],
   "source": [
    "Lik_R = RandomForestRegressor(n_estimators=512, n_jobs=6)\n",
    "Lik_R.fit(X[0:468480:32], Like_Train[0:468480:32])\n",
    "testing (M, Like_Test, Lik_R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d58a8bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>AdaBoostRegressor(learning_rate=0.01, n_estimators=5000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">AdaBoostRegressor</label><div class=\"sk-toggleable__content\"><pre>AdaBoostRegressor(learning_rate=0.01, n_estimators=5000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "AdaBoostRegressor(learning_rate=0.01, n_estimators=5000)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = AdaBoostRegressor(n_estimators=5000, learning_rate=0.01)\n",
    "clf.fit(X[0:468480:32], Z[0:468480:32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fab7eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l2 error: 1.8834456735387388 classification accuracy: 0.8319672131147541 2030 2440\n"
     ]
    }
   ],
   "source": [
    "output = Val_R.predict(M[0:78080:32])\n",
    "label = L[0:78080:32]\n",
    "\n",
    "k = 0\n",
    "l = 0\n",
    "\n",
    "for i in range(len(label)):\n",
    "    k = k + (output[i] - label[i])*(output[i] - label[i]) #square difference \n",
    "    \n",
    "    #a good guess\n",
    "    if (output[i] > 5 and label[i] > 5):\n",
    "        l = l + 1\n",
    "    elif (output[i] < 5 and label[i] <5):\n",
    "        l = l + 1\n",
    "\n",
    "print (\"l2 error:\", k/len(label), \"classification accuracy:\", l / len(label),l, len(label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c3c5e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf062de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc430fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f7413",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc12454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40abf463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d29aef1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6efc400",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
